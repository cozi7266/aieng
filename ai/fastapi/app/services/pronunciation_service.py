import os
import tempfile
import uuid
import subprocess
from typing import Dict, Optional
from fastapi import UploadFile
from google.cloud import speech
import Levenshtein
import wave
import logging
import re
from urllib.parse import unquote

logger = logging.getLogger(__name__)

def clean_text(text: str) -> str:
    """íŠ¹ìˆ˜ë¬¸ìž ì œê±° ë° ì†Œë¬¸ìž ë³€í™˜"""
    return re.sub(r'[^\w\s]', '', text.lower())

def get_duration(input_path: str) -> float:
    """FFmpegë¡œ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸"""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", input_path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True
        )
        return float(result.stdout.decode().strip())
    except Exception as e:
        logger.warning(f"[ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨] {input_path}: {str(e)}")
        return 0.0

async def convert_to_wav(input_path: str) -> str:
    """FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ìž…ë ¥ ì˜¤ë””ì˜¤ë¥¼ wav(16kHz, mono)ë¡œ ë³€í™˜"""
    output_path = os.path.join(tempfile.gettempdir(), f"{uuid.uuid4()}.wav")
    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_path, "-ar", "16000", "-ac", "1", "-f", "wav", output_path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True
        )
        return output_path
    except subprocess.CalledProcessError as e:
        logger.error(f"[FFmpeg ë³€í™˜ ì‹¤íŒ¨] {e.stderr.decode()}")
        raise RuntimeError("ì˜¤ë””ì˜¤ íŒŒì¼ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

async def evaluate_pronunciation(audio_file: UploadFile, expected_text: Optional[str] = None) -> Dict:
    try:
        expected_text = unquote(expected_text or "").strip()
    except Exception as e:
        logger.warning(f"[expected_text ë””ì½”ë”© ì‹¤íŒ¨] {e}")
        expected_text = ""

    logger.info(f"[STT í‰ê°€ ì‹œìž‘] ì—…ë¡œë“œëœ íŒŒì¼: {audio_file.filename}, ì˜ˆìƒ ë¬¸ìž¥: '{expected_text}'")

    ext = os.path.splitext(audio_file.filename)[-1].lower()

    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as temp_input_file:
        content = await audio_file.read()
        temp_input_file.write(content)
        temp_input_path = temp_input_file.name

    temp_wav_path = None

    try:
        # ëª¨ë“  í¬ë§· â†’ WAV ë³€í™˜
        temp_wav_path = await convert_to_wav(temp_input_path)
        audio_path = temp_wav_path
        encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16
        sample_rate = 16000
        try:
            with wave.open(audio_path, 'rb') as wav_file:
                sample_rate = wav_file.getframerate()
        except Exception as e:
            logger.warning(f"[ìƒ˜í”Œë ˆì´íŠ¸ í™•ì¸ ì‹¤íŒ¨] {str(e)}")

        # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
        duration = get_duration(audio_path)
        logger.info(f"[ì˜¤ë””ì˜¤ ê¸¸ì´] {audio_path} => {duration:.2f}ì´ˆ")
        if duration < 0.5:
            logger.warning(f"[ë¬´ì‹œë¨] ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (0.5ì´ˆ ë¯¸ë§Œ)")
            return {
                "recognized_text": "",
                "expected_text": expected_text,
                "accuracy": 0.0,
                "confidence": 0.0,
                "feedback": "ìŒì„±ì´ ë…¹ìŒë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§í•´ë³¼ê¹Œìš”? ðŸŽ¤"
            }

        # ëª¨ë¸ ìžë™ ì„ íƒ
        def select_model(text: Optional[str]) -> str:
            if not text:
                return "default"
            word_count = len(text.strip().split())
            return "command_and_search" if word_count <= 2 else "default"

        selected_model = select_model(expected_text)
        logger.info(f"[ëª¨ë¸ ì„ íƒ] '{expected_text}' â†’ ëª¨ë¸: {selected_model}")

        # Speech contexts ì„¤ì •
        speech_contexts = []
        if expected_text:
            try:
                speech_contexts.append(
                    speech.SpeechContext(
                        phrases=[expected_text],
                        boost=20.0
                    )
                )
            except Exception as e:
                logger.warning(f"[speech_contexts ìƒì„± ì‹¤íŒ¨] '{expected_text}' â†’ {e}")

        config = speech.RecognitionConfig(
            encoding=encoding,
            sample_rate_hertz=sample_rate,
            language_code="en-US",
            enable_automatic_punctuation=(selected_model == "default"),
            model=selected_model,
            use_enhanced=True,
            speech_contexts=speech_contexts
        )

        client = speech.SpeechClient()
        with open(audio_path, "rb") as f:
            content = f.read()

        audio = speech.RecognitionAudio(content=content)
        response = client.recognize(config=config, audio=audio)

        recognized_text = ""
        confidence = 0.0
        if response.results:
            recognized_text = response.results[0].alternatives[0].transcript
            confidence = response.results[0].alternatives[0].confidence

        logger.info(f"[STT ê²°ê³¼] ì¸ì‹ëœ ë¬¸ìž¥: '{recognized_text}'")

        # ë°œìŒ ìœ ì‚¬ë„ í‰ê°€
        accuracy = None
        feedback = "ìž˜í–ˆì–´ìš”! ðŸ‘"
        if expected_text:
            clean_recognized = clean_text(recognized_text)
            clean_expected = clean_text(expected_text)
            distance = Levenshtein.distance(clean_recognized, clean_expected)
            max_length = max(len(clean_recognized), len(clean_expected))
            accuracy = ((max_length - distance) / max_length) * 100

            if accuracy < 10:
                feedback = "ë‹¤ì‹œ í•œ ë²ˆ ë”°ë¼ ì½ì–´ ë³¼ê¹Œìš”? ðŸŽµ"
            else:
                feedback = "ìž˜í–ˆì–´ìš”! ðŸŒŸ"

        result = {
            "recognized_text": recognized_text,
            "expected_text": expected_text,
            "accuracy": round(accuracy, 2) if accuracy is not None else None,
            "confidence": round(confidence, 2),
            "feedback": feedback
        }

        logger.info(f"[STT í‰ê°€ ì™„ë£Œ] {result}")
        return result

    except Exception as e:
        logger.error(f"[STT ì˜¤ë¥˜] {str(e)}")
        raise e

    finally:
        for path in [temp_input_path, temp_wav_path]:
            try:
                if path and os.path.exists(path):
                    os.unlink(path)
            except Exception as e:
                logger.warning(f"[ìž„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨] {path}: {str(e)}")
